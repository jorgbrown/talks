name: title-layout
layout: true
class: center, middle, title

---
name: basic-layout
layout: true
class: left, top

---
name: title
template: title-layout

# Going Nowhere Faster
.footnote[Jorg Brown, <jorg.brown@gmail.com>, [@whatgoeshere1024](https://twitter.com/jorgbrown)]

???
Intro:
- I'm Jorg Brown
- I work on Google's C++ PL platform
- Obsessed with performance and optimization.

This is the third talk I'm giving on performance here at CppCon, super excited
to be back.

---
name: reflect
class: left, middle

1. Use efficient algorithms, fast data structures & idioms
1. Benchmark the code that matters, understand why
1. Use hybrid data structures to optimize allocations & cache locality

???
T+2 minutes -- take it slow to let folks settle

---
name: benchmark
template: title-layout

## You only care about performance that you benchmark!

---
name: data-oriented
template: basic-layout

## It's probably the data...
- Watch Mike Acton's talk; use data-oriented design
- See my talk about profiling, but use counters to track cache miss rates
- In the future, use tools like Efficiency Sanitizer to optimize data structures

???
30 seconds of talking here worthwhile. give some context for ESan.

---
name: ooo-dot-cpp
template: basic-layout

.left-col[
```cpp
#include <cassert>
#include <vector>

int dot(const std::vector<int> &a,
        const std::vector<int> &b) {
  int sum = 0;
  assert(a.size() == b.size());
  for (int i = 0; i < a.size(); ++i)
    sum += a[i] * b[i];
  return sum;
}
```
]
.right-col[
]

.footnote[Based on <http://llvm.org/devmtg/2013-04/olesen-slides.pdf>]

???
To examine how modern processors work, let's look at an example with less
control flow but more actual code. Dot product.

When we compile this code for x86 (and turn off a bunch of fancy compiler
optimizations) we get some fairly simple x86 code.

All of this is very directly based on the excellent talk about this subject by
Jakob Olesen at EuroLLVM in 2013.

---
name: ooo-dot-x86
template: basic-layout

.left-col[
```cpp
#include <cassert>
#include <vector>

int dot(const std::vector<int> &a,
        const std::vector<int> &b) {
  int sum = 0;
  assert(a.size() == b.size());
* for (int i = 0; i < a.size(); ++i)
*   sum += a[i] * b[i];
  return sum;
}
```
]
.right-col[
```text
.LBB0_2:
  movl    (%rsi,%rdi,4), %ecx
  imull   (%r8,%rdi,4), %ecx
  addl    %ecx, %eax
  addq    $1, %rdi
  cmpq    %rdi, %rdx
  ja      .LBB0_2
```
]

???
Here we have the x86 assembly for the inner loop, as generated by Clang.

---
name: ooo-dot-x86-units
template: basic-layout

.left-col[
.exec-units[
| Cycle | Load | ALU | ALU |
| ----: | ---- | --- | --- |
| 1     |      |     |     |
| 2     |      |     |     |
| 3     |      |     |     |
| 4     |      |     |     |
| 5     |      |     |     |
| 6     |      |     |     |
| 7     |      |     |     |
| 8     |      |     |     |
| 9     |      |     |     |
| 10    |      |     |     |
| 11    |      |     |     |
| 12    |      |     |     |
| 13    |      |     |     |]
]
.right-col[
```text
.LBB0_2:
  %ecx_0  = load (%rsi,%rdi_0,4)
  %tmp1_0 = load (%r8,%rdi_0,4)
  %ecx_1  = imul %tmp1_0, %ecx_0
  %eax_1  = add %ecx_1, %eax_0
  %rdi_1  = add $1, %rdi_0
  %flag_0 = cmp %rdi_1, %rdx; jna .LBB0_3
  %ecx_2  = load (%rsi,%rdi_1,4)
  %tmp1_1 = load (%r8,%rdi_1,4)
  %ecx_3  = imul %tmp1_1, %ecx_2
  %eax_2  = add %ecx_2, %eax_1
  %rdi_2  = add $1, %rdi_1
  %flag_1 = cmp %rdi_2, %rdx; jna .LBB0_3
  %ecx_4  = load (%rsi,%rdi_2,4)
  %tmp1_2 = load (%r8,%rdi_2,4)
  %ecx_5  = imul %tmp1_2, %ecx_4
  %eax_3  = add %ecx_5, %eax_2
  %rdi_3  = add $1, %rdi_2
  %flag_2 = cmp %rdi_3, %rdx; jna .LBB0_3
  ...

```
]

???
Modern processors have multiple execution units that can process instructions.
Let's imagine an x86 processor which has one unit that can load from memory, two
that can do arithmetic, and one that can do fused compare and branches. This
isn't necessarily an accurate model of real x86 processors, but is enough to
illustrate how things execute.

So here we're going to track each cycle on our processor and show which
instruction (named by its result) is executing on that unit during that cycle.

---
name: ooo-dot-x86-unit-it1-g1
template: basic-layout

.left-col[
.exec-units[
| Cycle | Load    | ALU     | ALU     |
| ----: | ----    | ---     | ---     |
| 1     | .h[%ecx_0]  |         |         |
| 2     | .h[%tmp1_0] |         |         |
| 3     |         |         |         |
| 4     |         |         |         |
| 5     |         |         |         |
| 6     |         | .h[%ecx_1]  |         |
| 7     |         |         |         |
| 8     |         |         |         |
| 9     |         |         | .h[%eax_1]  |
| 10    |         |         |         |
| 11    |         |         |         |
| 12    |         |         |         |
| 13    |         |         |         |]
]
.right-col[
```text
.LBB0_2:
* %ecx_0  = load (%rsi,%rdi_0,4)
* %tmp1_0 = load (%r8,%rdi_0,4)
* %ecx_1  = imul %tmp1_0, %ecx_0
* %eax_1  = add %ecx_1, %eax_0
  %rdi_1  = add $1, %rdi_0
  %flag_0 = cmp %rdi_1, %rdx; jna .LBB0_3
  %ecx_2  = load (%rsi,%rdi_1,4)
  %tmp1_1 = load (%r8,%rdi_1,4)
  %ecx_3  = imul %tmp1_1, %ecx_2
  %eax_2  = add %ecx_2, %eax_1
  %rdi_2  = add $1, %rdi_1
  %flag_1 = cmp %rdi_2, %rdx; jna .LBB0_3
  %ecx_4  = load (%rsi,%rdi_2,4)
  %tmp1_2 = load (%r8,%rdi_2,4)
  %ecx_5  = imul %tmp1_2, %ecx_4
  %eax_3  = add %ecx_5, %eax_2
  %rdi_3  = add $1, %rdi_2
  %flag_2 = cmp %rdi_3, %rdx; jna .LBB0_3
  ...

```
]

???

---
name: ooo-demo
template: title-layout

# What tools can we use to help with this?

???
T+15 minutes

Ok, this is *really* complicated. We're going to need help, we're going to need
tools. What tools do we have?

Let's go back to the clamp loop

- use perf counters to show IPC and lack of stalls w/ branch, but stalls w/ cmov.
T+18 minutes

- introduce IACA, show throughput analysis
T+23 minutes

---
name: conclusion
template: title-layout

## Hopefully this at least serves a basis for understanding loop performace!

---
name: questions
template: title-layout

# Questions?

???
